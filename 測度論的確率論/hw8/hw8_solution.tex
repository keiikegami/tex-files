\documentclass{article}
\usepackage[margin = .7in]{geometry}
\usepackage[dvipdfmx]{graphicx}
\usepackage{listings}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{bm}
\usepackage{mathrsfs}
\lstset{%
  language={python},
  basicstyle={\small},%
  identifierstyle={\small},%
  commentstyle={\small\itshape},%
  keywordstyle={\small\bfseries},%
  ndkeywordstyle={\small},%
  stringstyle={\small\ttfamily},
  frame={tb},
  breaklines=true,
  columns=[l]{fullflexible},%
  numbers=left,%
  xrightmargin=0zw,%
  xleftmargin=3zw,%
  numberstyle={\scriptsize},%
  stepnumber=1,
  numbersep=1zw,%
  lineskip=-0.5ex%
}

\begin{document}
\title{測度論的確率論 2018 S1S2 \\ 
Homework 8}
\author{経済学研究科現代経済コース修士1年 / 池上　慧 (29186009) / sybaster.x@gmail.com}
\maketitle

\section{2.2.1}
$E\left[ \frac{S_n}{n} \right] = \frac{S_n}{n} = v_n$であることより
\begin{align*}
	E\left[ \left( \frac{S_n}{n} - v_n \right)^2 \right] = Var\left(\frac{S_n}{n}\right) = \frac{1}{n^2} \left( Var(X_1) + Var(X_2) + \cdots + Var(X_n) \right)
\end{align*}
を得る。ただし、最後の等式は各確率変数が無相関であることによる。$n\to \infty$での挙動を考える。仮定より$\forall \epsilon > 0\ \exists I \ \text{s.t.}\ i \geq I \Rightarrow  \frac{Var(X_i)}{i} < \epsilon$であるので、
\begin{align*}
	\lim_{n\to \infty} E\left[ \left( \frac{S_n}{n} - v_n \right)^2 \right] &= \lim_{n\to \infty} \sum_{i=1}^{\infty} \frac{i}{n^2} \frac{Var(X_i)}{i}\\
	&\leq \lim_{n\to \infty} \sum_{i=1}^{I-1}  \frac{i}{n^2} \frac{Var(X_i)}{i} + \lim_{n\to \infty} \sum_{i=I}^{n}  \frac{i}{n^2} \frac{Var(X_i)}{i} \\
	&\leq \lim_{n\to \infty} \sum_{i=1}^{I-1}  \frac{i}{n^2} \frac{Var(X_i)}{i} +  \lim_{n\to \infty} \frac{\epsilon}{n^2} \sum_{i=I}^n i\\
	&\leq \frac{\epsilon}{2}
\end{align*}
従って任意の$\epsilon > 0$で上から押さえることができるので$\frac{S_n}{n} - v_n \to 0\ \text{in $L^2$}$である。チェビシェフの不等式より任意の$\epsilon > 0$に対して、
\begin{align*}
	P\left( \left| \frac{S_n}{n} - v_n \right| > \epsilon \right) \leq \frac{E\left[ \left( \frac{S_n}{n} - v_n \right)^2 \right]}{\epsilon^2} \to 0\ \text{as}\ n\to \infty
\end{align*}
であるので確かに確率収束もする。

\section{2.2.2}
\begin{align*}
	E\left[ \left(\frac{S_n}{n}\right)^2 \right] = \frac{1}{n^2} \sum_{1\geq i,j\geq n} E\left[ X_i X_j \right]
\end{align*}
である。コーシーシュワルツの不等式より、$E\left[ X_i X_j \right] \leq \left( E\left[ X_i^2 \right] E\left[ X_j^2 \right] \right)^{\frac{1}{2}} = r(0)$である。また仮定より、
\begin{align*}
	\forall \epsilon > 0, \exists K > 0\ \text{s.t.}\ k \geq K\ \Rightarrow\ r(k) < \epsilon
\end{align*}
である。これより、$|i-j| \leq K$に対しては$E[X_i X_j] \leq r(0)$とし、$|i-j| > K$に対しては$E[X_i X_j] \leq \epsilon$で抑えられる。すなわち、
\begin{align*}
	\frac{1}{n^2} \sum_{1\geq i,j\geq n} E\left[ X_i X_j \right] \leq \frac{1}{n^2} \left( n(2K-1)r(0) + n^2\epsilon \right) = \frac{2K+1}{n}r(0) + \epsilon
\end{align*}
である。$K$は$n$に依存しないので$\lim \frac{1}{n^2} E[S_n^2] \leq \epsilon$である。従って$0$に$L^2$収束するので$0$に確率収束する。

\section{2.2.3}
Th2.2.14の条件を満たすことを確認する。$U_i$が一様分布に従うことより以下が成立。
\begin{align*}
	E\left[ I_n \right] = E\left[ f(U_i) \right] = \int f(x) \mathrm{d}x
\end{align*}
さらに、$B$を$\mathbb{R}$上の可測集合とすると、$f$が可測関数であることより以下が成立する。
\begin{align*}
	P\left( \omega \in U_1^{-1}\left( f^{-1}(B) \right) \right) \times \cdots \times P\left( \omega \in U_n^{-1}\left( f^{-1}(B) \right) \right) = P\left( \omega \in \left(f\circ U_1\right)^{-1}(B) \right)\times \cdots \times  P\left( \omega \in \left(f\circ U_n\right)^{-1}(B) \right)
\end{align*}
また、
\begin{align*}
	P\left( \omega \in U_1^{-1}\left( f^{-1}(B) \right), \cdots, \omega \in U_n^{-1}\left( f^{-1}(B) \right) \right) = P\left( \omega \in \left(f\circ U_1\right)^{-1}(B), \cdots, \omega \in \left(f\circ U_n\right)^{-1}(B) \right)
\end{align*}
である。$\left\{ U_i \right\}$は独立であることより上二つの左辺は等しい。従って右辺も等しくなり、$\left\{ f(U_i) \right\}$も独立な確率変数である。以上でTh2.2.14の条件が成立することが確認されたので、$I_n \xrightarrow{p} \int_0^1 f(x) \mathrm{d}x$である。

次に$P\left( | I_n - I | > \frac{a}{\sqrt{n}} \right)$を推定するために一様分布の実現値$\left\{ u_i \right\}_{i=1}^n$を$M$セット発生させる。この時得られた$I_n$を$I_n^m$と記し、$\bar{I_n} = \frac{1}{M} \sum_{m=1}^M I_n^m$とする。
\begin{align*}
	P\left( | I_n - I | > \frac{a}{\sqrt{n}} \right) = E\left[ 1\left(  | I_n^m - I | > \frac{a}{\sqrt{n}} \right) \right]
\end{align*}
であるので、右辺のサンプル表記である$\frac{1}{M} \sum_{m=1}^M 1\left(  | I_n^m - \bar{I_n} | > \frac{a}{\sqrt{n}} \right)$が題意の推定をうまく行えることを以下で示す。
\begin{align*}
	E\left[ 1\left(  | I_n^m - \bar{I_n} | > \frac{a}{\sqrt{n}} \right) \right] &= P\left( | (I_n^m - I) + (I - \bar{I_n}) |  > \frac{a}{\sqrt{n}} \right) \\
	&\leq P\left( | I_n^m - I |+ |I - \bar{I_n}|  > \frac{a}{\sqrt{n}} \right)\\
	& \leq P\left( | I_n^m - I |> \frac{a}{\sqrt{n}} \right) + P\left( |I - \bar{I_n}|  > \frac{a}{\sqrt{n}} \right)
\end{align*}
$M$個のサンプルは独立に生成され、上より可積分なのでWLLNより、
\begin{align*}
\frac{1}{M} \sum_{m=1}^M 1\left(  | I_n^m - \bar{I_n} | > \frac{a}{\sqrt{n}} \right) \xrightarrow{p} E\left[ 1\left(  | I_n^m - \bar{I_n} | > \frac{a}{\sqrt{n}} \right) \right]
\end{align*}
である。さらに、チェビシェフの不等式より
\begin{align*}
	\| E\left[ 1\left(  | I_n^m - \bar{I_n} | > \frac{a}{\sqrt{n}} \right) \right] - P\left( | I_n^m - I |> \frac{a}{\sqrt{n}} \right)  \| &\leq P\left( |I - \bar{I_n}|  > \frac{a}{\sqrt{n}} \right)\\
	&\leq \frac{n}{a^2} E\left[ \left( \bar{I_n} - I \right)^2 \right]\\
	&= \frac{n}{Ma^2} Var\left(I_n^m \right)\\
	&= \frac{1}{a^2M} Var\left( f(U_i) \right)
\end{align*}
を得る。従って$M\to \infty$で$E\left[ 1\left(  | I_n^m - \bar{I_n} | > \frac{a}{\sqrt{n}} \right) \right] \to P\left( | I_n^m - I |> \frac{a}{\sqrt{n}} \right)$である。ここで「$a_n \xrightarrow{p} b_n \to b \Rightarrow a_n \xrightarrow{p} b$（主張$1$）」であることより
\begin{align*}
	\frac{1}{M} \sum_{m=1}^M 1\left(  | I_n^m - \bar{I_n} | > \frac{a}{\sqrt{n}} \right) \xrightarrow{p} P\left( | I_n^m - I |> \frac{a}{\sqrt{n}} \right) = P\left( | I_n - I |> \frac{a}{\sqrt{n}} \right)
\end{align*}
であるので推定できる。
\subsection{主張$1$の証明}
$a_n \xrightarrow{p} b_n \to b \Rightarrow a_n \xrightarrow{p} b$を示す。任意の$\epsilon, \delta > 0$に対して、
\begin{align*}
	\exists N\ \text{s.t.}\ n > N\ \Rightarrow\ P(\| a_n -b_n \| > \epsilon) \leq \delta
\end{align*}
である。また、
\begin{align*}
	\exists M\ \text{s.t.}\ m > M\ \Rightarrow\ \|b_m-b\| < \epsilon
\end{align*}
である。ここで三角不等式より、
\begin{align*}
	n > \max(N,M)\ \Rightarrow\ P\left( \| a_n - b \| > \epsilon \right) \leq P\left( \| a_n - b_n \| > \epsilon \right) + P\left( \| b_n - b \| > \epsilon \right) \leq \delta
\end{align*}
が成立するため、題意は示された。

\section{2.2.4}
まず絶対値の期待値が発散することを確認する。
\begin{align*}
	E\left[ |X_i| \right] = \sum_{k = 2}^{\infty} k \frac{C}{k^2 \log k} = C \lim_{N \to \infty} \sum_{k = 2}^{N} \frac{1}{k \log k}
\end{align*}
$k \geq 2$において$\frac{1}{k \log k}$が単調減少であることより積分判定法が使える。
\begin{align*}
	\int_2^{\infty} \frac{1}{x\log x} \mathrm{d}x = \int_2^{\infty} \frac{\left( \log x \right)^{\prime}}{\log x} \mathrm{d}x > \lim_{x\to \infty} \log \log x = \infty
\end{align*}
これより確かに先の期待値は発散する。一方で、$k P\left( |X_i| > k \right) \to 0\ \text{as}\ k \to \infty$は成立することが以下のようにして確認できる。
\begin{align*}
	k P\left( |X_i| > k \right) &= k \sum_{l = k+1}^{\infty} \frac{C}{l^2 \log l} \leq Ck \int_k^{\infty} \frac{1}{x^2 \log x} \mathrm{d}x\\
	&= Ck \int_{\log k}^{\infty} \frac{\exp(-z)}{z} \mathrm{d}z \leq C \frac{k}{\log k} \int_{\log k}^{\infty} \exp(-z) \mathrm{d}z = C \frac{1}{\log k} \to 0\ \text{as}\ k \to \infty
\end{align*}
従ってTh2.2.12が適用できて、
\begin{align*}
	\mu_n = E\left[ X_i 1\left( |X_i| \leq n \right) \right] = \sum_{k = 2}^{n} (-1)^k \frac{C}{k \log k}
\end{align*}
とおくと、$\frac{S_n}{n} - \mu_n \xrightarrow{p} 0$である。さらに「交項級数は各項の絶対値が単調減少で$0$に収束するなら収束する」ので、$\mu_n$がこの性質を満たすことから、$\mu_n \to \mu$なる$\mu$が存在する。以上より$\frac{S_n}{n} - \mu \xrightarrow{p} 0$である。


\section{2.2.5}
まず絶対値の期待値が発散することを示す。Lemma2.2.13より
\begin{align*}
	E\left[ |X_i| \right] = \int_e^{\infty} \frac{e}{x\log x} \mathrm{d}x = e\left[ \log \log x \right]_e^{\infty} = \infty
\end{align*}
であるので確かに期待値は発散する。しかし
\begin{align*}
	x P\left( |X_i| > x \right) = x \frac{e}{x \log x} = \frac{e}{\log x} \to 0\ \text{as}\ x\to \infty
\end{align*}
であるのでTheorem2.2.12が適用でき、
\begin{align*}
	\mu_n = E\left[ X_i 1\left(|X_i| \leq n\right) \right]
\end{align*}
とおくと$\frac{S_n}{n} - \mu_n \xrightarrow{p} 0$である。


\section{2.2.6}
フビニの定理より$E[X]$は以下のように変形できる。
\begin{align*}
	E\left[ X \right] = E\left[ \sum_{n = 1}^{\infty} 1(X \geq n) \right] = \sum_{n = 1}^{\infty} E[1(X \geq n)] = \sum_{n = 1}^{\infty} P(X \geq n)
\end{align*}
また同じくフビニの定理より、
\begin{align*}
	E[X^2] = E\left[ 2 \sum_{n=1}^X n - X \right] = E\left[ \sum_{n=1}^{\infty} (2n-1) 1(X \geq n) \right] = \sum_{n=1}^{\infty} (2n-1) P(X \geq n)
\end{align*}
を得る。

\end{document}





























